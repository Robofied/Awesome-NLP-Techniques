{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lemmatization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYY6L8NADmZi"
      },
      "source": [
        "# **Lemmatization**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEN83v6cEJ-k"
      },
      "source": [
        "### **What is Lemmatization?**\n",
        "\n",
        "Lemmatization is similar to stemming but it brings context to the words. \n",
        "The output after lemmatization is called ‘lemma’, which is a root word rather than root stem, the output of stemming. After lemmatization, we will get a valid word that means the same thing.\n",
        "Lemmatization is preferred over Stemming because lemmatization does morphological analysis of the words.\n",
        "One major difference with stemming is that lemmatize takes a part of speech parameter, “pos” If not supplied, the default is “noun.”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCZxuxETFrnb"
      },
      "source": [
        "### **Need of Lemmatization**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. Used in comprehensive retrieval systems like search engines.\n",
        "2. Used in compact indexing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzWzQeoeM9nU"
      },
      "source": [
        "### **Various approaches to Lemmatization**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpwbIvJzNPsj"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### **1.  Wordnet Lemmatizer (with POS tag)**\n",
        "\n",
        "<hr/>\n",
        "\n",
        "We add a tag with a particular word defining its type (verb, noun, adjective etc). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9mJX72yFQgb",
        "outputId": "f2406b85-55c4-47f2-898b-8b85e9c732ae"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "  \n",
        "\n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "better : good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4AFcwd_NdO8"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### **2.  TextBlob**\n",
        "\n",
        "<hr/>\n",
        "\n",
        "TextBlob is a python library used for processing textual data. It provides a simple API to access its methods and perform basic NLP tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtFhVKF5OeL9",
        "outputId": "d1e74998-a94f-4989-cacf-e87b7ec9c5c2"
      },
      "source": [
        "from textblob import TextBlob, Word \n",
        "nltk.download('punkt')\n",
        "  \n",
        "sentence = 'We develop open-source solutions for developers which empowers them so that they can make better products for the world. We educate people about Artificial Intelligence, its scope and impact via resources and tutorials..'\n",
        "  \n",
        "s = TextBlob(sentence) \n",
        "lemmatized_sentence = \" \".join([w.lemmatize() for w in s.words]) \n",
        "  \n",
        "print(lemmatized_sentence) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "We develop open-source solution for developer which empowers them so that they can make better product for the world We educate people about Artificial Intelligence it scope and impact via resource and tutorial\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQRs8aHyP2QI"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### **3. spaCy**\n",
        "\n",
        "<hr/>\n",
        "\n",
        "spaCy is an open-source python library that parses and “understands” large volumes of text. Separate models are available that cater to specific languages (English, French, German, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrixrXBqQgJ3",
        "outputId": "1b7ed375-4436-4896-e9f5-d54ec3f6fda8"
      },
      "source": [
        "import spacy \n",
        "nlp = spacy.load('en_core_web_sm') \n",
        "  \n",
        "\n",
        "doc = nlp(u'We develop open-source solutions for developers which empowers them so that they can make better products for the world. We educate people about Artificial Intelligence, its scope and impact via resources and tutorials.') \n",
        "  \n",
        "# Create list of tokens \n",
        "tokens = [] \n",
        "for token in doc: \n",
        "    tokens.append(token) \n",
        "  \n",
        "print(tokens)\n",
        "  \n",
        "lemmatized_sentence = \" \".join([token.lemma_ for token in doc]) \n",
        "  \n",
        "print(lemmatized_sentence) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[We, develop, open, -, source, solutions, for, developers, which, empowers, them, so, that, they, can, make, better, products, for, the, world, ., We, educate, people, about, Artificial, Intelligence, ,, its, scope, and, impact, via, resources, and, tutorials, .]\n",
            "-PRON- develop open - source solution for developer which empower -PRON- so that -PRON- can make well product for the world . -PRON- educate people about Artificial Intelligence , -PRON- scope and impact via resource and tutorial .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guZpsi8DJRDv"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### **Difference Between Stemming and Lemmatization**\n",
        "\n",
        "<hr/>\n",
        "\n",
        "\n",
        "|   S.NO    | Stemming      | Lemmatization |\n",
        "| ----------- | ----------- | ----------- |\n",
        "| 1     | Stemming is faster because it chops words without knowing the context of the word in given sentences.      |    Lemmatization is slower as compared to stemming but it knows the context of the word before proceeding.|\n",
        "|   2   | It is a rule-based approach.  |   It is a dictionary-based approach.      | \n",
        "|  3|   Accuracy is less.  |  Accuracy is more as compared to Stemming. |\n",
        "| 4 |  When we convert any word into root-form then stemming may create the non-existence meaning of a word. |    Lemmatization always gives the dictionary meaning word while converting into root-form.    |\n"
      ]
    }
  ]
}