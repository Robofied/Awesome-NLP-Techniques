{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['robofied', 'is', 'a', 'comprehensive', 'artificial', 'intelligence', 'platform', 'based', 'in', 'gurugram,haryana', 'working', 'towards', 'democratizing', 'safe', 'common', 'goal', 'of', 'singularity.', 'at', 'robofied,', 'we', 'are', 'doing', 'research', 'speech,', 'natural', 'language,', 'and', 'machine', 'learning.', 'develop', 'open-source', 'solutions', 'for', 'developers', 'which', 'empowers', 'them', 'so', 'that', 'they', 'can', 'make', 'better', 'products', 'the', 'world.', 'educate', 'people', 'about', 'intelligence,', 'its', 'scope', 'impact', 'via', 'resources', 'tutorials.']\n",
      "['robofied', 'comprehensive', 'artificial', 'intelligence', 'platform', 'based', 'in', 'gurugram,haryana', 'working', 'towards', 'democratizing', 'safe', 'common', 'goal', 'of', 'singularity.', 'at', 'robofied,', 'we', 'are', 'doing', 'research', 'speech,', 'natural', 'language,', 'and', 'machine', 'learning.', 'develop', 'open-source', 'solutions', 'for', 'developers', 'which', 'empowers', 'them', 'so', 'that', 'they', 'can', 'make', 'better', 'products', 'the', 'world.', 'educate', 'people', 'about', 'intelligence,', 'its', 'scope', 'impact', 'via', 'resources', 'tutorials.']\n",
      "[1, 1, 3, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def vectorize(tokens):\n",
    "    ''' This function takes list of words in a sentence as input \n",
    "    and returns a vector of size of filtered_vocab.It puts 0 if the \n",
    "    word is not present in tokens and count of token if present.'''\n",
    "    vector=[]\n",
    "    for w in filtered_vocab:\n",
    "        vector.append(tokens.count(w))\n",
    "    return vector\n",
    "def unique(sequence):\n",
    "    \n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "stopwords=[\"to\",\"is\",\"a\"]\n",
    "\n",
    "special_char=[\",\",\":\",\" \",\";\",\".\",\"?\"]\n",
    "\n",
    "string1=\"Robofied is a comprehensive Artificial Intelligence platform based in Gurugram,Haryana working towards democratizing safe artificial intelligence towards a common goal of Singularity. At Robofied, we are doing research in speech, natural language, and machine learning. We develop open-source solutions for developers which empowers them so that they can make better products for the world. We educate people about Artificial Intelligence, its scope and impact via resources and tutorials.\"\n",
    "\n",
    "#convert them to lower case\n",
    "string1=string1.lower()\n",
    "\n",
    "#split the sentences into tokens\n",
    "tokens1=string1.split()\n",
    "\n",
    "\n",
    "\n",
    "#create a vocabulary list\n",
    "vocab=unique(tokens1)\n",
    "print(vocab)\n",
    "\n",
    "#filter the vocabulary list\n",
    "filtered_vocab=[]\n",
    "for w in vocab: \n",
    "    if w not in stopwords and w not in special_char: \n",
    "        filtered_vocab.append(w)\n",
    "print(filtered_vocab)\n",
    "\n",
    "#convert sentences into vectords\n",
    "vector1=vectorize(tokens1)\n",
    "print(vector1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
